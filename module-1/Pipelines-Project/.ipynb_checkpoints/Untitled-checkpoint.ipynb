{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's the list of 30 companies the portfolio managers would like \n",
    "# us to analyze\n",
    "\n",
    "def get_tickers(path):\n",
    "    companies = pd.read_csv(path)\n",
    "    ticker_list = list(companies['Ticker'])\n",
    "    print('Retrieved', str(len(ticker_list)),'ticker symbols.')\n",
    "    return ticker_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, will need to extract the ticker symbol for each company\n",
    "# and make a call to the Quandl API in order to retrieve the historical prices \n",
    "# for that company's stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices(ticker):\n",
    "    print('Retrieving data for', ticker)\n",
    "    quandl.ApiConfig.api_key = 'CDmDYdJsPfiXTBfxL_zs' \n",
    "    prices = quandl.get('WIKI/'+ ticker)['Adj. Close'].reset_index()\n",
    "    prices['Ticker']= ticker #new column with prices\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 30 ticker symbols.\n",
      "Retrieving data for AAPL\n"
     ]
    },
    {
     "ename": "LimitExceededError",
     "evalue": "(Status 429) (Quandl Error QELx01) You have exceeded the anonymous user limit of 50 calls per day. To make more calls today, please register for a free Quandl account and then include your API key with your requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLimitExceededError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0c7661ec8dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticker_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-7132cee129d0>\u001b[0m in \u001b[0;36mget_prices\u001b[0;34m(ticker)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_prices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Retrieving data for'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquandl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WIKI/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj. Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/quandl/get.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dataset, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataset_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'column_index'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'column_index'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'column_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_column_not_found\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/quandl/model/dataset.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self, **options)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mupdated_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mupdated_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhandle_not_found_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/quandl/operations/list.py\u001b[0m in \u001b[0;36mall\u001b[0;34m(cls, **options)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstructed_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_dates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/quandl/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(cls, http_verb, url, **options)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mabs_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mApiConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_verb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/quandl/connection.py\u001b[0m in \u001b[0;36mexecute_request\u001b[0;34m(cls, http_verb, url, **options)\u001b[0m\n\u001b[1;32m     48\u001b[0m                                        **options)\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_api_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/quandl/connection.py\u001b[0m in \u001b[0;36mhandle_api_error\u001b[0;34m(cls, resp)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_klass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_letter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuandlError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mLimitExceededError\u001b[0m: (Status 429) (Quandl Error QELx01) You have exceeded the anonymous user limit of 50 calls per day. To make more calls today, please register for a free Quandl account and then include your API key with your requests."
     ]
    }
   ],
   "source": [
    "data = []\n",
    "ticker_list = get_tickers('/Users/ajiacovic/Downloads/companies.csv')\n",
    "\n",
    "for ticker in ticker_list:\n",
    "    prices = get_prices(ticker)\n",
    "    data.append(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When this is run, you should see the following output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRANGLE-TIME!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first thing we are going to do is concatenate the list of data frames using the concat method \n",
    "so that they are all in a single data frame. Then, we are going to pivot the data using the \n",
    "pivot_table method so that the rows each represent a single date, each column represents a company, \n",
    "and the values in the pivot table are the company's stock price on a specific date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_pivot(data, rows, columns, values):\n",
    "    df = pd.concat(data, sort=True)\n",
    "    pivot = df.pivot_table(values = values,columns = columns, index = rows)\n",
    "    return pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have company stock prices per day, but the metrics we need \n",
    "for our analysis need to be calculated from the stocks' returns or \n",
    "the percentage change in the stock's price from day to day. We can \n",
    "create another pivot table containing these returns pretty easily \n",
    "by using the pct_change method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_returns(df):\n",
    "    returns = df.pct_change()#returns the pct change between current row and last\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS-TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have daily historical stock price returns for each company of interest. Our data is now at a point where we can be analyzed, so let's jump right into it.\n",
    "\n",
    "We are going to create a function that filters our returns to just the last X number of days and computes the mean return for each company and the standard deviation of returns. From there, we divide each company's mean by its standard deviation to get the average return per unit of risk metric the portfolio managers wanted to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_risk_ratio(df, days=30):\n",
    "    means = pd.DataFrame(df.tail(days).mean())\n",
    "    std = pd.DataFrame(df.tail(days).std())\n",
    "    ratios = pd.concat([means, std], axis=1).reset_index()\n",
    "    ratios.columns = ['Company', 'Mean', 'Std']\n",
    "    ratios['Ratio'] = ratios['Mean']/ratios['Std']\n",
    "    return ratios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nce we have this, we can sort in descending order and filter for just the top 10 companies that had the highest ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = ratios.sort_values('Ratio', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once we have this top 10 list, we can then compare the correlations of their returns over varying periods of time so that the portfolio managers can limit their risk by not investing in stocks whose returns are too highly correlated with each other using the .corr method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_matrix(df, days=30):\n",
    "    corr_matrix = df.tail(days).corr()\n",
    "    return corr_matrix\n",
    "\n",
    "target_list = returns[list(top10['Company'])]\n",
    "correlation = corr_matrix(target_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPORTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have completed the necessary steps to analyze the data, the next step is to produce and distribute the reports. First, we are going to put together a horizontal bar chart that shows the top 10 companies and their return vs. risk ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def barchart(df, x, y, length=8, width=14, title=\"\"):\n",
    "    df = df.sort_values(x, ascending=False)\n",
    "    plt.figure(figsize=(width,length))\n",
    "    chart = sns.barplot(data=df, x=x, y=y)\n",
    "    plt.title(title + \"\\n\", fontsize=16)\n",
    "    return chart\n",
    "\n",
    "bar_plot = barchart(top10, 'Ratio', 'Company', title='Stock Return vs. Risk Ratios')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will produce a correlation matrix heatmap that visually shows the correlations between each company's returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def correlation_plot(corr, title=\"\"):\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    #Triu is upper triangle of the correlation\n",
    "\n",
    "    plt.subplots(figsize=(15, 10))\n",
    "    cmap = sns.diverging_palette(6, 255, as_cmap=True)\n",
    "    #diverging_palette = 6 is scale, 255 is color\n",
    "    chart = sns.heatmap(corr, mask=mask, cmap=cmap, center=0, linewidths=.5, annot=True, fmt='.2f')\n",
    "    plt.title(title, fontsize=16)\n",
    "    return chart\n",
    "\n",
    "corr_plot = correlation_plot(correlation, title='Stock Return Correlation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save each chart we create as a .PNG image file so that the portfolio managers can view them and make their investment decisions based on the information presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_viz(chart, title):\n",
    "    fig = chart.get_figure()\n",
    "    fig.savefig(title + '.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have most of the code base, it only takes a little bit of modification and reorganization to structure this so that it is repeatable for 90, 180, and 360 day time periods. In a Python (.py) file, we will perform all our imports first, then include each the functions we wrote above, create new functions for each pipeline stage that wraps the rest of our code, and finally include an \"if main\" statement at the bottom that executes everything for each time period requested.\n",
    "\n",
    "The complete code should look something like the following and should produce a total of six charts - a bar chart and a correlation heatmap for 90, 180, and 360 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def get_tickers(path):\n",
    "    companies = pd.read_csv(path)\n",
    "    ticker_list = list(companies['Ticker'])\n",
    "    print('Retrieved', str(len(ticker_list)), 'ticker symbols.')\n",
    "    return ticker_list\n",
    "\n",
    "def get_prices(ticker):\n",
    "    print('Retrieving data for', ticker)\n",
    "    quandl.ApiConfig.api_key = 'CDmDYdJsPfiXTBfxL_zs' \n",
    "    prices = quandl.get('WIKI/' + ticker)['Adj. Close'].reset_index()\n",
    "    prices['Ticker'] = ticker\n",
    "    return prices\n",
    "\n",
    "def concat_pivot(data, rows, columns, values):\n",
    "    df = pd.concat(data, sort=True)\n",
    "    pivot = df.pivot_table(values=values, columns=columns, index=rows)\n",
    "    return pivot\n",
    "\n",
    "def compute_returns(df):\n",
    "    returns = df.pct_change()\n",
    "    return returns\n",
    "\n",
    "def return_risk_ratio(df, days=30):\n",
    "    means = pd.DataFrame(df.tail(days).mean())\n",
    "    std = pd.DataFrame(df.tail(days).std())\n",
    "    ratios = pd.concat([means, std], axis=1).reset_index()\n",
    "    ratios.columns = ['Company', 'Mean', 'Std']\n",
    "    ratios['Ratio'] = ratios['Mean']/ratios['Std']\n",
    "    return ratios\n",
    "\n",
    "def corr_matrix(df, days=30):\n",
    "    corr_matrix = df.tail(days).corr()\n",
    "    return corr_matrix\n",
    "\n",
    "def barchart(df, x, y, length=8, width=14, title=\"\"):\n",
    "    df = df.sort_values(x, ascending=False)\n",
    "    plt.figure(figsize=(width,length))\n",
    "    chart = sns.barplot(data=df, x=x, y=y)\n",
    "    plt.title(title + \"\\n\", fontsize=16)\n",
    "    return chart\n",
    "\n",
    "def correlation_plot(corr, title=\"\"):\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    plt.subplots(figsize=(15, 10))\n",
    "    cmap = sns.diverging_palette(6, 255, as_cmap=True)\n",
    "    \n",
    "    chart = sns.heatmap(corr, mask=mask, cmap=cmap, center=0, linewidths=.5, annot=True, fmt='.2f')\n",
    "    plt.title(title, fontsize=16)\n",
    "    return chart\n",
    "\n",
    "def save_viz(chart, title):\n",
    "    fig = chart.get_figure()\n",
    "    fig.savefig(title + '.png')\n",
    "\n",
    "def acquire():\n",
    "    data = []\n",
    "\n",
    "    ticker_list = get_tickers('/Users/ajiacovic/Downloads/companies.csv')\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        prices = get_prices(ticker)\n",
    "        data.append(prices)\n",
    "    return data\n",
    "\n",
    "def wrangle(data):\n",
    "    pivot = concat_pivot(data, 'Date', 'Ticker', 'Adj. Close')\n",
    "    returns = compute_returns(pivot)\n",
    "    return returns\n",
    "\n",
    "def analyze(returns, days=30):\n",
    "    ratios = return_risk_ratio(returns, days=days)\n",
    "    top10 = ratios.sort_values('Ratio', ascending=False).head(10)\n",
    "    \n",
    "    target_list = returns[list(top10['Company'])]\n",
    "    correlation = corr_matrix(target_list)\n",
    "    return top10, correlation\n",
    "\n",
    "def report(top10, correlation):\n",
    "    bar_plot = barchart(top10, 'Ratio', 'Company', title='Stock Return vs. Risk Ratios - ' + str(day) + ' Days')\n",
    "    save_viz(bar_plot, 'Return vs. Risk Top 10 - ' + str(day) + ' Days')\n",
    "    \n",
    "    corr_plot = correlation_plot(correlation, title='Stock Return Correlation - ' + str(day) + ' Days')\n",
    "    save_viz(corr_plot, 'Correlation Plot - ' + str(day) + ' Days')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = acquire()\n",
    "    returns = wrangle(data)\n",
    "\n",
    "    num_days = [90,180,360]\n",
    "\n",
    "    for day in num_days:\n",
    "        top10, correlation = analyze(returns, days=day)\n",
    "        report(top10, correlation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the Python file as stock_analysis.py and run it from the command line as follows.\n",
    "\n",
    "$ python stock_analysis.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
